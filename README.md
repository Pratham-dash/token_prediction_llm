# token_prediction_llm
the LLM will predict the next word which will complete the sentence that is hard coded inside the code. (The output gives me an idea about the peculiar behaviour of LLMs)
